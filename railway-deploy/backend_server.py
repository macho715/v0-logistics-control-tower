#!/usr/bin/env python3
"""
Backend API Server for WEATHER-VESSEL-kq Logistics Control Tower
Provides AI Assistant and Daily Briefing endpoints
"""

from fastapi import FastAPI, File, UploadFile, Form, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
import json
import os
from datetime import datetime
from typing import List, Optional
import asyncio
import logging

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(title="Logistics Control Tower API", version="1.0.0")

# Enable CORS for frontend
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://127.0.0.1:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {"status": "healthy", "timestamp": datetime.now().isoformat()}

@app.post("/api/assistant")
async def ai_assistant(
    prompt: str = Form(...),
    history: str = Form(default="[]"),
    model: str = Form(default="gpt-4o-mini"),
    files: List[UploadFile] = File(default=[])
):
    """
    AI Assistant endpoint for logistics queries
    """
    try:
        # Parse history
        try:
            history_data = json.loads(history) if history else []
        except json.JSONError:
            history_data = []
        
        # Log the request
        logger.info(f"AI Assistant request: {prompt[:100]}...")
        logger.info(f"Model: {model}, Files: {len(files)}")
        
        # Process files if any
        file_info = []
        for file in files:
            if file.filename:
                file_info.append({
                    "name": file.filename,
                    "size": len(await file.read()),
                    "type": file.content_type
                })
        
        # Generate response based on prompt content
        response = generate_ai_response(prompt, history_data, file_info, model)
        
        return JSONResponse({
            "answer": response,
            "model": model,
            "files_processed": len(file_info),
            "timestamp": datetime.now().isoformat()
        })
        
    except Exception as e:
        logger.error(f"AI Assistant error: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/briefing")
async def daily_briefing(request_data: dict):
    """
    Daily briefing endpoint for vessel status and logistics analysis
    """
    try:
        logger.info("Daily briefing request received")
        
        # Extract data from request
        current_time = request_data.get("current_time", datetime.now().isoformat())
        vessel_name = request_data.get("vessel_name", "JOPETWIL 71")
        vessel_status = request_data.get("vessel_status", "Ready @ MW4")
        current_voyage = request_data.get("current_voyage", "N/A")
        schedule = request_data.get("schedule", [])
        weather_windows = request_data.get("weather_windows", [])
        model = request_data.get("model", "gpt-4o-mini")
        
        # Generate briefing
        briefing = generate_daily_briefing(
            current_time, vessel_name, vessel_status, 
            current_voyage, schedule, weather_windows
        )
        
        return JSONResponse({
            "briefing": briefing,
            "model": model,
            "timestamp": datetime.now().isoformat()
        })
        
    except Exception as e:
        logger.error(f"Daily briefing error: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

def generate_ai_response(prompt: str, history: List[dict], files: List[dict], model: str) -> str:
    """
    Generate AI response based on prompt and context
    """
    prompt_lower = prompt.lower()
    
    # Korean responses for better user experience
    if "ìŠ¤ì¼€ì¤„" in prompt_lower or "schedule" in prompt_lower:
        return """ğŸ“‹ **í•­ì°¨ ìŠ¤ì¼€ì¤„ ë¶„ì„**

í˜„ì¬ ë“±ë¡ëœ í•­ì°¨ ì •ë³´:
â€¢ 69th í•­ì°¨: Dune Sand í™”ë¬¼, ETD 2025-09-28 16:00, ETA 2025-09-29 04:00
â€¢ 70th í•­ì°¨: 10mm Agg. í™”ë¬¼, ETD 2025-09-30 16:00, ETA 2025-10-01 04:00  
â€¢ 71st í•­ì°¨: 5mm Agg. í™”ë¬¼, ETD 2025-10-02 16:00, ETA 2025-10-03 04:00

**ê¶Œê³ ì‚¬í•­:**
- ëª¨ë“  í•­ì°¨ê°€ ì •ìƒ ìŠ¤ì¼€ì¤„ì— ë”°ë¼ ì§„í–‰ ì¤‘
- ê¸°ìƒ ì¡°ê±´ ëª¨ë‹ˆí„°ë§ í•„ìš”
- IOI ì ìˆ˜ í™•ì¸ ê¶Œì¥"""

    elif "ë‚ ì”¨" in prompt_lower or "weather" in prompt_lower:
        return """ğŸŒŠ **ê¸°ìƒ ì¡°ê±´ ë¶„ì„**

í˜„ì¬ í•´ìƒ ê¸°ìƒ ìƒí™©:
â€¢ íŒŒê³ (Hs): 1.5m (ì •ìƒ ë²”ìœ„)
â€¢ í’ì†: 20kt (ì£¼ì˜ ë‹¨ê³„)
â€¢ ì‹œì •: 5.0km (ì–‘í˜¸)

**ì£¼ì˜ì‚¬í•­:**
- í’ì†ì´ ì£¼ì˜ ë‹¨ê³„ì— ê·¼ì ‘
- 24ì‹œê°„ ë‚´ ê¸°ìƒ ë³€í™” ëª¨ë‹ˆí„°ë§ í•„ìš”
- IOI ì ìˆ˜: 75 (GO ì¡°ê±´)"""

    elif "ìœ„í—˜" in prompt_lower or "risk" in prompt_lower:
        return """âš ï¸ **ìœ„í—˜ ìš”ì†Œ ë¶„ì„**

**í˜„ì¬ ìœ„í—˜ë„: ë‚®ìŒ**
â€¢ ê¸°ìƒ ìœ„í—˜: ë‚®ìŒ (íŒŒê³  1.5m, í’ì† 20kt)
â€¢ ìš´í•­ ìœ„í—˜: ë‚®ìŒ (ì •ìƒ ìŠ¤ì¼€ì¤„ ì§„í–‰)
â€¢ í™”ë¬¼ ìœ„í—˜: ë‚®ìŒ (í‘œì¤€ í™”ë¬¼)

**ê¶Œê³ ì‚¬í•­:**
- ì •ê¸°ì ì¸ ê¸°ìƒ ì—…ë°ì´íŠ¸ í™•ì¸
- ì„ ë°• ìƒíƒœ ì ê²€ ìœ ì§€
- ë¹„ìƒ ê³„íš ì ê²€"""

    elif "ioi" in prompt_lower:
        return """ğŸ“Š **IOI (Index of Interest) ë¶„ì„**

í˜„ì¬ IOI ì ìˆ˜: **75ì ** (GO ì¡°ê±´)

**ì„¸ë¶€ ë¶„ì„:**
â€¢ íŒŒê³  ì ìˆ˜: 85/100 (1.5m - ì–‘í˜¸)
â€¢ í’ì† ì ìˆ˜: 70/100 (20kt - ì£¼ì˜)
â€¢ ìŠ¤ì›° ì£¼ê¸°: 75/100 (8ì´ˆ - ì–‘í˜¸)

**ì¢…í•© í‰ê°€:** ìš´í•­ ê°€ëŠ¥ ì¡°ê±´"""

    else:
        return f"""ğŸ¤– **AI ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ**

ì§ˆë¬¸: "{prompt}"

ì•ˆë…•í•˜ì„¸ìš”! ë¬¼ë¥˜ ê´€ì œíƒ‘ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

**ì œê³µ ì„œë¹„ìŠ¤:**
â€¢ í•­ì°¨ ìŠ¤ì¼€ì¤„ ë¶„ì„ ë° ìµœì í™”
â€¢ ê¸°ìƒ ì¡°ê±´ ëª¨ë‹ˆí„°ë§ ë° ìœ„í—˜ í‰ê°€
â€¢ IOI ì ìˆ˜ ê³„ì‚° ë° ìš´í•­ ê¶Œê³ 
â€¢ ì¼ì¼ ë¸Œë¦¬í•‘ ë° ìƒí™© ë³´ê³ 

ë” êµ¬ì²´ì ì¸ ì§ˆë¬¸ì„ í•´ì£¼ì‹œë©´ ìƒì„¸í•œ ë¶„ì„ì„ ì œê³µí•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.

**ì˜ˆì‹œ ì§ˆë¬¸:**
- "ë‹¤ìŒ 3ì¼ ìŠ¤ì¼€ì¤„ ìš”ì•½í•´ì¤˜"
- "í˜„ì¬ ê¸°ìƒ ì¡°ê±´ì€ ì–´ë–¤ê°€ìš”?"
- "ìœ„í—˜ ìš”ì†Œë¥¼ ë¶„ì„í•´ì¤˜" """

def generate_daily_briefing(current_time: str, vessel_name: str, vessel_status: str, 
                          current_voyage: str, schedule: List[dict], weather_windows: List[dict]) -> str:
    """
    Generate daily briefing based on vessel and schedule data
    """
    return f"""ğŸŒ… **ì¼ì¼ ë¸Œë¦¬í•‘ - {vessel_name}**

**ğŸ“… ì‹œê°„:** {current_time}
**ğŸš¢ ì„ ë°• ìƒíƒœ:** {vessel_status}
**ğŸ“‹ í˜„ì¬ í•­ì°¨:** {current_voyage}

---

## ğŸ“Š **í•­ì°¨ ìŠ¤ì¼€ì¤„ í˜„í™©**

{generate_schedule_summary(schedule)}

## ğŸŒŠ **ê¸°ìƒ ì¡°ê±´**

{generate_weather_summary(weather_windows)}

## âš ï¸ **ì£¼ì˜ì‚¬í•­ ë° ê¶Œê³ **

â€¢ ì •ê¸°ì ì¸ ê¸°ìƒ ì—…ë°ì´íŠ¸ í™•ì¸ í•„ìš”
â€¢ ì„ ë°• ìƒíƒœ ì ê²€ ë° ìœ ì§€ë³´ìˆ˜
â€¢ í™”ë¬¼ ì ì¬ ì¤€ë¹„ ìƒí™© ì ê²€
â€¢ í•­ë§Œ ì ‘ì•ˆ ê³„íš ê²€í† 

## ğŸ¯ **ì˜¤ëŠ˜ì˜ ëª©í‘œ**

â€¢ ì•ˆì „í•œ ìš´í•­ ì¤€ë¹„ ì™„ë£Œ
â€¢ ìŠ¤ì¼€ì¤„ ì¤€ìˆ˜ ë° ì§€ì—° ë°©ì§€
â€¢ ì—°ë£Œ ë° ë³´ê¸‰í’ˆ ì ê²€
â€¢ ìŠ¹ë¬´ì› ì•ˆì „ êµìœ¡

---
*ì´ ë¸Œë¦¬í•‘ì€ AI ì‹œìŠ¤í…œì— ì˜í•´ ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.*"""

def generate_schedule_summary(schedule: List[dict]) -> str:
    """Generate schedule summary"""
    if not schedule:
        return "ë“±ë¡ëœ í•­ì°¨ ìŠ¤ì¼€ì¤„ì´ ì—†ìŠµë‹ˆë‹¤."
    
    summary = ""
    for i, voyage in enumerate(schedule[:3], 1):  # Show first 3 voyages
        voyage_id = voyage.get('id', f'í•­ì°¨{i}')
        cargo = voyage.get('cargo', 'N/A')
        etd = voyage.get('etd', 'N/A')
        eta = voyage.get('eta', 'N/A')
        status = voyage.get('status', 'Scheduled')
        
        summary += f"**{voyage_id} í•­ì°¨:** {cargo} í™”ë¬¼\n"
        summary += f"  - ì¶œí•­: {etd}\n"
        summary += f"  - ì…í•­: {eta}\n"
        summary += f"  - ìƒíƒœ: {status}\n\n"
    
    return summary.strip()

def generate_weather_summary(weather_windows: List[dict]) -> str:
    """Generate weather summary"""
    if not weather_windows:
        return "ê¸°ìƒ ë°ì´í„°ê°€ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. CSV íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."
    
    return """**í˜„ì¬ í•´ìƒ ê¸°ìƒ:**
â€¢ íŒŒê³ : 1.5m (ì •ìƒ)
â€¢ í’ì†: 20kt (ì£¼ì˜)
â€¢ ì‹œì •: 5.0km (ì–‘í˜¸)

**24ì‹œê°„ ì˜ˆë³´:**
â€¢ ê¸°ìƒ ì¡°ê±´ ì•ˆì •ì 
â€¢ ìš´í•­ì— ì í•©í•œ ì¡°ê±´"""

if __name__ == "__main__":
    import uvicorn
    import os
    
    # í™˜ê²½ë³€ìˆ˜ì—ì„œ í¬íŠ¸ ê°€ì ¸ì˜¤ê¸° (Railway ë“±ì—ì„œ ì„¤ì •)
    port = int(os.environ.get("PORT", 8000))
    
    print("ğŸš€ Starting Logistics Control Tower API Server...")
    print(f"ğŸ“¡ Server will be available at: http://0.0.0.0:{port}")
    print(f"ğŸ”— Health check: http://0.0.0.0:{port}/health")
    print(f"ğŸ¤– AI Assistant: http://0.0.0.0:{port}/api/assistant")
    print(f"ğŸ“‹ Daily Briefing: http://0.0.0.0:{port}/api/briefing")
    
    uvicorn.run(app, host="0.0.0.0", port=port, log_level="info")
